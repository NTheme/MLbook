\section{Модели зависимости и обучения}

Предполагается, что имеется пространство $X$ признаковых описаний исследуемых объектов, и пространство $Y$ ответов.
Также существует неизвестная целевая зависимость $y\colon X\to Y$, значения которой (в случае обучения с учителем) известны только на некоторых элементах $x = (x_1, \ldots, x_m) \in X^m$.
Требуется восстановить эту неизвестную зависимость (а точнее, приблизить её как можно точнее).

Чтобы восстановить зависимость, вводят некоторое семейство $W$ параметров (весов в линейном случае) и функцию \( f\colon X\times W\to Y\), которая по параметрам восстанавливает зависимость $y$. 
Для всякого \( w\in W\) функция \( a_w\colon X\to Y\), определённая как \( a_w(x) = f(w, x)\), называется моделью зависимости.

Нашей задачей теперь является найти такую $w^* \in W$, что функция \( a_{w^*}\) хорошо приближает зависимость $y$.

\section{Функция потерь и функционал качества}

Чтобы формализовать понятие <<хорошо приближает>>, вводят т.н. функцию потерь \( L\colon Y^2\to \mathbb{R} \), которая является неотрицательно определённой симметричной формой. Типичные примеры:
\begin{itemize}
    \item \(L(y^*, y) = [y^*\neq y]\) для задач классификации,

    \item \(L(y^*, y) = (y^* - y)^2\) для задач регрессии.
\end{itemize}

Функционал качества \( Q \colon Y^X \times X^m \times Y^m\) характеризует средние потери и определяется как
\[
    Q(a, x, y) = \frac{1}{m} \sum_{i=1}^m L(a(x_i), y_i).
\]
В терминах теории вероятностей это значение называют эмпирическим риском.

Принцип минимизации эмпирического риска утверждает, что для решения поставленной задачи нужно найти
\[
    w^* = \arg\min_{w\in W} Q(a_w, x, y).
\]

\subsection*{Задача 1}

    Сформулируйте задачу минимизации эмпирического риска в терминах метода максимума правдоподобия.

\subsection*{Задача 2}

    Сведите задачу с функцией потерь MAPE к задаче с функцией MAE, но с относительными весами.
    
\subsection*{Задача 3}
    Допустим, мы решаем задачу проведения разделяющей гиперплоскости, но в аффинном пространстве. Как будет выглядеть функция потерь в таком случае?


\section*{Переобучение. Борьба с переобучением}

Переобучение (overfitting) - это явление, при котором модель машинного обучения показывает существенно лучшие результаты на обучающих данных по сравнению с тестовыми. Формально переобученность определяется как разность между ошибками на контрольной и обучающей выборках:

\[\delta(\mu, X^l, X^k) = \nu(\mu(X^l), X^k) - \nu(\mu(X^l), X^l)\]

где:
\begin{itemize}
   \item $\mu$ - метод обучения
   \item $X^l$ - обучающая выборка
   \item $X^k$ - контрольная выборка  
   \item $\nu$ - частота ошибок
\end{itemize}

О наличии переобучения говорят, когда $\delta > \varepsilon$ для некоторого порогового значения $\varepsilon$.

\subsection*{Признаки переобучения}

1. Большая разница между качеством работы на обучающей и тестовой/валидационной выборках.

2. Продолжение улучшения качества на обучении при ухудшении на валидации в процессе обучения.

3. Слишком много параметров модели

4. Слишком большие значения весов

5. Избыточное количество признаков

\subsection*{Основные методы борьбы с переобучением}

1. \textbf{Регуляризация} - добавление штрафа за сложность модели:

L1-регуляризация:
\[J(w) = L(w) + \lambda\sum_{i=1}^n |w_i|\]

L2-регуляризация:
\[J(w) = L(w) + \lambda\sum_{i=1}^n w_i^2\]

где $L(w)$ - исходная функция потерь, $\lambda$ - коэффициент регуляризации.

2. \textbf{Использование кросс-валидации}
Кросс-валидация - оценка качества и подбор гиперпараметров на разных разбиениях выборки:
  \begin{itemize}
     \item K-fold: Выборка разбивается на k равных частей. На каждой итерации одна часть используется для валидации, остальные k-1 частей - для обучения. Итоговая оценка усредняется по всем разбиениям:
     \item Leave-one-out (LOO): Частный случай k-fold CV при k = n, где n - размер выборки. На каждой итерации только один объект используется для валидации. Этот метод дает несмещенную оценку ошибки, но требует большого числа итераций обучения.
  \end{itemize}

3. \textbf{Уменьшение сложности модели}:
  \begin{itemize}
     \item Сокращение числа параметров
     \item Отбор значимых признаков
     \item Упрощение архитектуры
  \end{itemize}

4. \textbf{Увеличение объема обучающей выборки}

\subsection*{Оценка эффективности борьбы с переобучением}

1. Мониторинг динамики ошибок на обучающей и валидационной выборках.

2. Расчет величины переобученности $\delta$.

3. Оценка значимости признаков и параметров модели.

4. Анализ сложности модели относительно размера выборки.

\subsection*{Задача 1}
В процессе обучения нейронной сети для задачи бинарной классификации получены следующие значения ошибок по эпохам обучения:

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Эпоха & Ошибка на обучении & Ошибка на валидации \\
\hline
1 & 0.40 & 0.42 \\
5 & 0.25 & 0.30 \\
10 & 0.15 & 0.25 \\
15 & 0.08 & 0.28 \\
20 & 0.03 & 0.35 \\
25 & 0.01 & 0.45 \\
\hline
\end{tabular}
\end{center}

Определите оптимальное количество эпох обучения для минимизации эффекта переобучения и обоснуйте свой выбор. Рассчитайте величину переобученности $\delta$ для последней эпохи.

\textbf{Решение:}
Для определения оптимального количества эпох проанализируем динамику ошибок:
\begin{enumerate}
    \item До 10-й эпохи обе ошибки монотонно убывают, что говорит о нормальном процессе обучения.
    \item После 10-й эпохи ошибка на обучении продолжает уменьшаться, но ошибка на валидации начинает расти, что является явным признаком переобучения.
    \item Оптимальное количество эпох - 10, так как при дальнейшем обучении начинается переобучение
\end{enumerate}

Величина переобученности на последней эпохе:
$$\delta = \nu(X^k) - \nu(X^l) = 0.45 - 0.01 = 0.44$$

\textbf{Ответ:} 10 эпох; $\delta = 0.44$

\subsection*{Задача 2}
Дана выборка из 8 объектов с целевой переменной $y \in \{0,1\}$ и одним признаком $x$:
$$(x_1=1, y_1=0), (x_2=2, y_2=0), (x_3=3, y_3=1), (x_4=4, y_4=1),$$
$$(x_5=5, y_5=1), (x_6=6, y_6=1), (x_7=7, y_7=0), (x_8=8, y_8=0)$$

Модель представляет собой пороговое правило вида:
$$a(x) = [x \geq t]$$
где $t$ - порог, $[...]$ - индикатор.

Используя метод полного скользящего контроля (leave-one-out cross-validation), найдите оптимальное значение порога $t$, минимизирующее среднюю ошибку на контроле.

\textbf{Решение:}
1) При leave-one-out каждый объект по очереди становится контрольным, а остальные - обучающими.

2) Возможные значения порога $t$ следует искать между соседними значениями признака $x$, принадлежащими разным классам. Таким образом, получаем множество потенциальных порогов:
$t \in \{1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5\}$

3) Рассмотрим подробно процесс для порога $t = 2.5$. Запишем пороговое правило:
$$a(x) = [x \geq 2.5]$$

Для первого объекта $(x_1 = 1, y_1 = 0)$:
$$a(1) = [1 \geq 2.5] = 0$$
Правильный ответ $y_1 = 0$, следовательно ошибка на первом объекте:
$$e_1 = |y_1 - a(x_1)| = |0 - 0| = 0$$

Для второго объекта $(x_2 = 2, y_2 = 0)$:
$$a(2) = [2 \geq 2.5] = 0$$
$$e_2 = |y_2 - a(x_2)| = |0 - 0| = 0$$

Для третьего объекта $(x_3 = 3, y_3 = 1)$:
$$a(3) = [3 \geq 2.5] = 1$$
$$e_3 = |y_3 - a(x_3)| = |1 - 1| = 0$$

Аналогично для остальных объектов получаем вектор ошибок:
$$e = (0, 0, 0, 0, 0, 0, 1, 1)$$

Средняя ошибка для порога $t = 3.5$ равна:
$$\text{err}(2.5) = \frac{1}{8}\sum_{i=1}^8 e_i = \frac{0 + 0 + 0 + 0 + 0 + 0 + 1 + 1}{8} = \frac{2}{8} = 0.25$$

Проведем аналогичные вычисления для остальных порогов и получим:

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Значение порога $t$ & Средняя ошибка err$(t)$ & Количество ошибок \\
\hline
1.5 & 0.375 & 3 \\
2.5 & 0.250 & 2 \\
3.5 & 0.375 & 3 \\
4.5 & 0.500 & 4 \\
5.5 & 0.625 & 5 \\
6.5 & 0.750 & 6 \\
7.5 & 0.625 & 5 \\
\hline
\end{tabular}
\end{center}

\textbf{Ответ:} Оптимальное значение порога $t = 2.5$, что дает среднюю ошибку 0.25.

\subsection*{Задача 3}
При обучении модели классификации изображений исследователь записывал значения accuracy каждые 3 эпохи для двух различных архитектур нейронных сетей (A и B). Размер обучающей выборки: 500 изображений.
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
& \multicolumn{2}{|c|}{Модель A} & \multicolumn{2}{|c|}{Модель B} \\
\hline
Эпоха & Обучение & Валидация & Обучение & Валидация \\
\hline
3 & 0.65 & 0.62 & 0.70 & 0.68 \\
6 & 0.75 & 0.70 & 0.82 & 0.75 \\
9 & 0.85 & 0.72 & 0.95 & 0.69 \\
12 & 0.95 & 0.68 & 0.98 & 0.63 \\
\hline
\end{tabular}
\end{center}
Требуется:

Определить, какая из моделей показывает более сильное переобучение. Обосновать ответ.
Рассчитать величину переобученности $\delta$ для обеих моделей на последней эпохе.
Для модели с более сильным переобучением указать оптимальное количество эпох обучения.

\textbf{Решение:}
Давайте проанализируем поведение каждой модели.
Для модели A:
На первых эпохах наблюдается нормальное обучение - точность растет как на обучающей, так и на валидационной выборке. После 6-й эпохи начинается расхождение: точность на обучении продолжает расти, а на валидации начинает падать. К 12-й эпохе разрыв становится существенным.
Для модели B:
Начальное обучение идет быстрее, чем у модели A. Однако уже после 6-й эпохи наблюдается резкое расхождение между обучающей и валидационной точностью. К 9-й эпохе точность на обучении достигает 0.95, но на валидации падает до 0.69.
Рассчитаем величину переобученности $\delta$ на последней эпохе:

Модель A: $\delta_A = 0.68 - 0.95 = -0.27$
Модель B: $\delta_B = 0.63 - 0.98 = -0.35$

Модель B показывает более сильное переобучение, потому что:

Больше абсолютная величина $\delta$ на последней эпохе (-0.35 против -0.27)
Более быстрая скорость расхождения метрик после 6-й эпохи
Более высокая точность на обучении при более низкой точности на валидации

Для модели B оптимальным является остановка на 6-й эпохе, так как:

Достигнута хорошая точность на валидации (0.75)
Разрыв между обучением и валидацией еще не критический
После этой эпохи начинается явное переобучение

\textbf{Ответ:}
Модель B показывает более сильное переобучение ($\delta_B = -0.35$), в то время как ($\delta_A = -0.27$). Оптимальное количество эпох для модели B - 6 эпох, что обеспечивает наилучшее качество на валидации (0.75) без явного переобучения.

\section{Линейные модели классификации и регрессии}

Обе линейные модели описываются следующим образом.
На пространстве $X$ объектов заданы числовые признаки \( f_1, \ldots, f_n\colon X\to\mathbb{R}\). По заданному вектору \(w\in\mathbb{R}^n\) весов определяются предсказания объектов
\[
    a(x,w) := \sum_{i=1}^n w_if_i(x) = w^Tf(x)
\]
в задаче регрессии; в задаче классификации от этого выражения берётся знак. При фиксированной (но неизвестной) таргет-функции \( y\colon X\to Y\) определяется функция потерь \( L(x, w)\), которая в задаче классификации равна индикатору того, что \(a(x,w) \neq y(x)\), а в задаче регрессии равна
\[
    L(x,w) = \lvert{a(x,w)-y(x)}\rvert
    \quad\text{или}\quad
    L(x,w) = \lvert{a(x,w)-y(x)}\rvert^2,
\]
или любому другому симметричному неотрицательному функционалу.
Далее в обеих моделях нужно решить задачу оптимизации
\[
    \sum_{i=1}^N L(x_i, w) \to \min_{w},
\]
где $x_i$ суть элементы выборки размера $N$. То есть, неформально, нужно придумать линейную модель, которая по $x \in X$ восстанавливает $y(x) \in Y$.

\section{Метод наименьших квадратов}

В методе наименьших квадратов в задаче линейной регресии необходимо решить задачу минимизации функционала
\[
    \lVert{w^Tf(X) - Y}\rVert_2^2 \to \min_w,
\]
где $Y$ это вектор из таргетов $y_i = y(X_i)$, $X$ это вектор наблюдений, а $f(X)$ это матрица признаков размера $n \times N$.
Из линейной алгебры известно, что решением задачи минимизации является вектор
\[
    \hat{w} = (f(X)f(X)^T)^{-1}f(X)Y.
\]
Известно, что он является несмещённой оценкой параметра $w$, и, кроме того, наилучшей оценкой этого параметра в классе всех линейных оценок вида $A(X)Y$ с квадратичной функцией потерь.

В гауссовской линейной модели дополнительно известно, что
\[
    Y \sim N\left( w^Tf(X),\ \sigma^2 I_{N\times N} \right).
\]
Тогда оценка $\hat{w}$ является оптимальной оценкой вектора $w$ в среднеквадратичном подходе в классе несмещённых оценок.

\subsection*{Задача 1}

    Дан набор точек в $\mathbb{R}^3$, отмеченных $\pm1$.
    Необходимо описать задачу проведения разделяющей плоскости, проходящей через начало координат, как задачу линейной регрессии.

\subsection*{Задача 2}

    В задаче линейной регрессии получить несмещённую оценку ошибки $\sigma^2$.
    
\subsection*{Задача 3}

    В гауссовской линейной модели найдите оптимальную оценку параметра $w_1 + \ldots +w_n$ и её распределение.

\section{Скользящий контроль}

Скользящий контроль (или кросс-проверка, кросс-валидация, англ. cross-validation, CV) — это метод эмпирической оценки  обобщающей способности алгоритмов, когда они обучаются на примерах из данных.

Метод основан на использовании некоторого числа разбиений исходной выборки на два подмножества: обучающей и контрольной подвыборок. Для каждого разбения выполняется обучение алгоритма на обучающей подвыборке, а затем рассчитывается средняя ошибка на контрольной подвыборке. Итоговой оценкой скользящего контроля является среднее значение ошибки по всем контрольным подвыборкам.

При условии независимости выборки средняя ошибка кросс-валидации даёт несмещённую оценку вероятности ошибки. Это преимущество выделяет её по сравнению со средней ошибкой на обучающей выборке, которая может быть смещена (занижена) из-за эффекта переобучения.

Скользящий контроль является стандартным методом для тестирования и сравнения алгоритмов классификации, регрессии и прогнозирования.

\section{Определения и обозначения}

Рассмотрим задачу обучения с учителем.

Пусть $X$ — множество, содержащее описания объектов, а $Y$ — множество возможных ответов.

Предположим, что имеется конечная выборка прецедентов $X^L = \{(x_i, y_i)\}_{i=1}^L \subset X \times Y$.

Задан алгоритм обучения — отображение $\mu$, которое сопоставляет произвольной конечной выборке прецедентов $X^m$ некоторую функцию (алгоритм) $a : X \to Y$.

Качество алгоритма $a$ оценивается по произвольной выборке прецедентов $X^m$ с использованием функционала качества $Q(a, X^m)$. Для процедуры скользящего контроля способ вычисления данного функционала может варьироваться, однако обычно он аддитивен по элементам выборки:

\[
Q(a, X^m) = \frac{1}{m} \sum_{x_i \in X^m} \mathcal{L}(a(x_i), y_i),
\]

где $\mathcal{L}(a(x_i), y_i)$ — неотрицательная функция потерь, показывающая величину ошибки алгоритма $a(x_i)$ при истинном ответе $y_i$.

\subsection{Процедура скользящего контроля}

Рассмотрим выборку $X^L$, которая разбивается на $N$ различных способов на две непересекающиеся подвыборки: $X^L = X^m_n \cup X^k_n$, где $X^m_n$ — обучающая подвыборка размера $m$, а $X^k_n$ — контрольная подвыборка длины $k = L - m$, при этом $n = 1, \ldots, N$ обозначает номер разбиения.

Для каждого разбиения $n$ рассчитывается алгоритм $a_n = \mu(X^m_n)$ и вычисляется значение функционала качества $Q_n = Q(a_n, X^k_n)$. Среднее арифметическое значений $Q_n$ по всем разбиениям называют оценкой по методу скользящего контроля:

\[
CV(\mu, X^L) = \frac{1}{N} \sum_{n=1}^N Q(\mu(X^m_n), X^k_n).
\]

Разные методы скользящего контроля отличаются как видами функционала качества, так и способами разбиения выборки.

\subsection{Доверительное оценивание}

Кроме среднего значения качества на контроле, строятся также доверительные интервалы.

\textbf{Непараметрическая оценка доверительного интервала.}
\newline
Cтроится вариационный ряд значений $Q_n = Q(a_n, X^k_n)$, где $n = 1, \ldots, N$:

\[
Q^{(1)} \leq Q^{(2)} \leq \cdots \leq Q^{(N)}.
\]

\textbf{Утверждение 1.} Если разбиения осуществлялись случайно, независимо и равновероятно, то с вероятностью $\eta = \frac{t}{N+1}$ значение случайной величины $Q(a(X^m), X^k)$ не превосходит $Q^{(N-t+1)}$.

\textbf{Следствие 1.} Значение случайной величины $Q(a(X^m), X^k)$ не превосходит $Q^{(N)}$ с вероятностью $\eta = \frac{1}{N+1}$.

В частности, для получения верхней оценки с надёжностью 95\% достаточно взять $N=20$ разбиений.

\textbf{Утверждение 2.} Если разбиения осуществлялись случайно, независимо и равновероятно, то с вероятностью $\eta = \frac{2t}{N+1}$ значение случайной величины $Q(a(X^m), X^k)$ не выходит за границы доверительного интервала $\left[ Q^{(t)}, Q^{(N-t+1)} \right]$.

\textbf{Следствие 2.} Значение случайной величины $Q(a(X^m), X^k)$ не выходит за границы вариационного ряда $\left[ Q^{(1)}, Q^{(N)} \right]$ с вероятностью $\eta = \frac{2}{N+1}$.

В частности, для получения двусторонней оценки с надёжностью 95\% достаточно взять $N=40$ разбиений.

\textbf{Параметрические оценки доверительного интервала} основываются на априорном предположении о виде распределения случайной величины $Q(a(X^m), X^k)$. Если априорные предположения не выполняются, доверительный интервал может оказаться сильно смещённым. В частности, если предположения о нормальности распределения не выполнены, то нельзя использовать стандартное «правило двух сигм» или «трёх сигм». Джон Лангфорд в своей диссертации \cite{Langford2002} указывает на распространённую ошибку, когда правило двух сигм применяется к функционалу частоты ошибок, имеющему на самом деле биномиальное распределение. Однако биномиальным распределением в общем случае тоже нельзя пользоваться, поскольку в результате обучения по случайным подвыборкам $X^m$ вероятность ошибки алгоритма $a(X^m)$ оказывается случайной величиной. Следовательно, случайная величина $Q(a(X^m), X^k)$ описывается не биномиальным распределением, а (неизвестной) смесью биномиальных распределений. Аппроксимация смеси биномиальным распределением может приводить к ошибочному сужению доверительного интервала. Приведённые выше непараметрические оценки лишены этого недостатка.

\subsection{Стратификация}

Стратификация выборки представляет собой метод, направленный на уменьшение разброса (дисперсии) оценок, получаемых при скользящем контроле, что позволяет получить более узкие доверительные интервалы и более точные верхние оценки.

Процесс стратификации заключается в том, чтобы заранее разделить выборку на несколько частей (страты), и при разбиении на обучающую выборку длины $m$ и контрольную выборку длины $k$ обеспечить, чтобы каждая страта была представлена в обучении и контроле в одинаковых пропорциях $m:k$.

\textbf{Стратификация классов} в задачах классификации означает, что каждый класс делится между обучением и контролем в пропорции $m:k$.

\textbf{Стратификация по вещественному признаку} осуществляется следующим образом: объекты выборки сортируются по какому-либо критерию, например, по возрастанию значения одного из признаков. Затем выборка разбивается на $k$ последовательных страт одинаковой длины (с точностью до 1). При формировании контрольных выборок из каждой страты выбирается по одному объекту — либо с заданным порядковым номером внутри страты, либо случайным образом.


\section{Разновидности скользящего контроля}
Существует несколько различных методов скользящего контроля, которые могут отличаться по способу разбиения выборки.
\subsection{Полный скользящий контроль (complete CV)}
Оценка скользящего контроля строится по всем возможным $N = C_L^k$ разбиениям. В зависимости от длины обучающей выборки $k$ различают следующие варианты:
\begin{itemize}

\item \textbf{Частный случай при $k=1$ — контроль по отдельным объектам (leave-one-out CV)}

Как было показано, контроль по отдельным объектам является асимптотически оптимальным при определённых условиях, а именно:

\[
\frac{L_n(\hat{m})}{\inf_{m \in M_n} L_n(m)} \to 1 \quad \text{по вероятности},
\]

где:

\begin{itemize}
  \item $M_n$ — класс сравниваемых моделей;
  \item $L_n(m)$ — среднеквадратичная ошибка при выборе $m$-ой модели;
  \item $\hat{m} = \arg \min_{m \in M_n} \text{CV}(m)$.
\end{itemize}

\item \textbf{Общий случай при $k>2$}
\end{itemize}

В этом случае число разбиений $N = C_L^k$ становится очень большим, даже для сравнительно малых значений $k$, что делает практическое применение данного метода затруднительным. Для такого случая полный скользящий контроль используется либо в теоретических исследованиях \cite{Voronov2004}, либо в редких ситуациях, когда удаётся вывести эффективную вычислительную формулу. Например, для метода \textit{$k$ ближайших соседей} существует такая формула, которая позволяет эффективно выбирать параметр $k$.

\medskip
На практике чаще применяются другие варианты скользящего контроля.

\subsection{Случайные разбиения}

Разбиения $n = 1, \ldots, N$ выбираются случайным образом, независимо и с одинаковой вероятностью из множества всех возможных $C_L^k$ разбиений. Именно для такого случая верны приведённые выше оценки доверительных интервалов. На практике эти оценки обычно применяются без изменений и к другим методам разбиения выборки.

\subsection{Контроль на отложенных данных (hold-out CV)}
Оценка модели с использованием метода скользящего контроля основана на одном случайном разбиении выборки, где $N=1$.

Однако этот метод имеет несколько значительных недостатков:

\begin{enumerate}
    \item Часто приходится оставлять слишком много объектов в контрольной подвыборке, что приводит к сокращению обучающей выборки. Это уменьшение объема обучающей выборки вызывает смещение оценки (пессимистически завышенную вероятность ошибки).
    \item Оценка модели значительно зависит от конкретного разбиения данных, в то время как более предпочтительно, чтобы она характеризовала исключительно алгоритм обучения, а не случайность разбиения.
    \item Дисперсия оценки может быть высокой. Она может быть снижена путём усреднения оценок по нескольким разбиениям.
\end{enumerate}

Важно различать два типа контроля по отложенным данным и по тестовой выборке:

\begin{itemize}
    \item \textbf{Контроль по отложенным данным (Hold-out)} — оценка вероятности ошибки производится для классификатора, построенного по всей выборке.
    \item \textbf{Контроль по тестовой выборке (Test-set)} — оценка вероятности ошибки вычисляется для классификатора, обученного на обучающей подвыборке.
\end{itemize}

\subsection{Контроль по отдельным объектам (leave-one-out CV)}

Метод leave-one-out (LOO) является частным случаем полной кросс-валидации с использованием скользящего контроля при \( k = 1 \), что означает \( N = L \), где \( L \) — количество объектов в выборке. Это один из наиболее популярных вариантов скользящей кросс-валидации.

Основное преимущество LOO заключается в том, что каждый объект участвует в процессе контроля ровно один раз, при этом размер обучающих подвыборок лишь на единицу меньше общей выборки.

Однако метод LOO имеет и ряд недостатков, основным из которых является высокая вычислительная нагрузка, поскольку для каждого объекта выборки требуется провести обучение модели заново. В некоторых случаях, когда используемые алгоритмы обучения позволяют быстро адаптировать внутренние параметры при замене одного объекта на другой, процесс LOO можно значительно ускорить.

\subsection{Контроль по q блокам (q-fold CV)}

В методе \( q \)-fold кросс-валидации выборка случайным образом делится на \( q \) непересекающихся блоков, каждый из которых имеет одинаковую (или почти одинаковую) длину \( k_1, \ldots, k_q \):

\[
X^L = X^{k_1}_1 \cup \cdots \cup X^{k_q}_q, \quad k_1 + \dots + k_q = L.
\]

Каждый блок поочередно используется в качестве контрольной подвыборки, а обучение модели проводится на оставшихся \( q-1 \) блоках. Критерий ошибки определяется как среднее значение ошибки на контрольной подвыборке:

\[
CV(\mu, X^L) = \frac{1}{q} \sum_{n=1}^q Q \left( \mu \left( X^L \setminus X^{k_n}_n \right), X^{k_n}_n \right),
\]

где \( Q \) — функция потерь. Этот метод представляет собой компромисс между подходами LOO, hold-out и случайными разбиениями. С одной стороны, обучение проводится только \( q \) раз, а не \( L \). С другой стороны, длина обучающих подвыборок, равная \( L \frac{q-1}{q} \) с точностью до округления, практически не отличается от длины всей выборки \( L \). Обычно выборку делят случайным образом на 10 или 20 блоков.

\subsection{Контроль по r×q блокам (r×q-fold CV)}
Контроль с использованием \(r \times q\)-кратного разбиения (или \(r \times q\)-fold кросс-валидации) представляет собой метод, при котором процедура \(q\)-кратной кросс-валидации повторяется \(r\) раз. В каждом повторении данные случайным образом делятся на \(q\) непересекающихся блоков, обеспечивая полное покрытие выборки. Этот метод сохраняет все преимущества стандартной \(q\)-кратной кросс-валидации, добавляя при этом гибкость в выборе количества разбиений.

Данный подход стратифицированного скользящего контроля считается одной из базовых методик для оценки и сравнения производительности алгоритмов классификации. Он широко используется в таких системах, как WEKA и «Полигон алгоритмов».

Метод скользящего контроля применяется также в задачах прогнозирования.


\section{Скользящий контроль в задачах прогнозирования}

В задачах прогнозирования, динамического обучения, обучения с подкреплением и активного обучения примеры часто линейно упорядочены по времени их появления. В таких случаях возможности применения различных вариантов скользящего контроля ограничены.

\subsection{Контроль с нарастающей длиной обучения}  Предполагается, что обучающая подвыборка включает все предыдущие наблюдения: \( X^m_n = \{x_1, \ldots, x_n\} \). Контрольная подвыборка состоит из последующих наблюдений: \( X^k_n = \{x_{n+\delta+1}, \ldots, x_{n+\delta+k}\} \), где \(\delta \geq 0\) — величина задержки прогноза (как правило, \(\delta = 0\)). Момент «текущего времени» \(n\) перемещается по выборке:

\[
CV(\mu, X^L) = \frac{1}{T_2 - T_1 + 1} \sum_{n=T_1}^{T_2} Q \left(\mu(X^m_n), X^k_n\right),
\]

где \(T_1\) — минимальная длина обучающей выборки, необходимая для корректной работы алгоритма обучения \(\mu\), \(T_2 = L - \delta - k\).

Так как длина обучающей подвыборки \(m = n\) увеличивается со временем, точность прогнозов алгоритма может постепенно возрастать. Этот эффект может быть нежелательным, если цель скользящего контроля — объективная оценка качества алгоритма обучения.

\subsection{Контроль с фиксированной длиной обучения} Отличается от метода с нарастающей длиной тем, что размер обучающей подвыборки \(m\) остаётся постоянным, включающим только последние \(m\) примеров временного ряда: \( X^m_n = \{x_{n-m+1}, \ldots, x_n\} \). В этом случае минимальная длина обучающей выборки принимается равной \(T_1 = m\).


\section{Недостатки скользящего контроля}
\begin{itemize}
\item При использовании скользящего контроля обучение выполняется \( N \) раз, что связано с высокими вычислительными затратами. 
\item Оценка скользящего контроля предполагает наличие заранее заданного алгоритма обучения \( \mu \), но она не раскрывает, какими свойствами должны обладать "хорошие" алгоритмы обучения и как их можно построить. В этом смысле теоретические оценки обобщающей способности могут давать полезные рекомендации.

\item Попытка применить скользящий контроль как критерий оптимизации в процессе обучения приводит к утрате его несмещённости, что увеличивает риск переобучения. 
\item Скользящий контроль предоставляет несмещённую точечную оценку риска, но не интервальную. На данный момент нет методов, которые позволяли бы на основе скользящего контроля строить точные доверительные интервалы для риска, то есть для математического ожидания потерь (включая вероятность ошибочной классификации).
\end{itemize}

\section{Применение скользящего контроля}

Скользящий контроль широко используется на практике для настройки некоторых ключевых параметров, которые, как правило, определяют структуру или сложность модели алгоритма и имеют ограниченное количество возможных значений.

Примеры применения:

\begin{itemize}
    \item Выбор модели из ограниченного набора альтернативных алгоритмов.
    \item Оптимизация параметра регуляризации, включая:
    \begin{itemize}
        \item параметр регуляризации в гребневой регрессии;
        \item параметр весового затухания (weight decay) в нейронных сетях;
        \item параметр \( C \) в методе опорных векторов.
    \end{itemize}
    \item Настройка ширины окна в методах:
    \begin{itemize}
        \item парзеновского окна;
        \item ближайшего соседа;
        \item ядерного сглаживания.
    \end{itemize}
    \item Оптимизация количества нейронов в скрытом слое многослойной нейронной сети.
    \item Выбор информативного набора признаков.
    \item Сокращение решающего дерева.
    \item Минимизация структурного риска.
\end{itemize}

\begin{thebibliography}{5}

\bibitem{Voronov2004}
Воронцов К. В. Комбинаторный подход к оценке качества обучаемых алгоритмов. — Математические вопросы кибернетики. М.: Физматлит, 2004.

\bibitem{Efron1988}
Эфрон Б. Нетрадиционные методы многомерного статистического анализа. — М: Финансы и статистика. — 1988.

\bibitem{Langford2002}
Langford J. Quantitatively Tight Sample Complexity Bounds. — Carnegie Mellon Thesis. — 2002. — 124 с.
\bibitem{Kohavi2002}
Kohavi R. A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection. — 14th International Joint Conference on Artificial Intelligence, Palais de Congres Montreal, Quebec, Canada. — 1995. — С. 1137-1145.
\bibitem{Mullin2000}
Mullin M., Sukthankar R. Complete Cross-Validation for Nearest Neighbor Classifiers. — Proceedings of International Conference on Machine Learning. — 2000. — С. 1137-1145.

\end{thebibliography}

\section*{Задача: Cross-Validation (LOOCV)}

У вас есть набор данных, состоящий из 6 объектов:
\[
D = \{ (x_1, y_1), (x_2, y_2), (x_3, y_3), (x_4, y_4), (x_5, y_5), (x_6, y_6) \},
\]
где \( y \) — целевая переменная, которая может принимать значение \( 0 \) или \( 1 \).

Простая линейная модель для предсказания \( y \) задана как:
\[
y = a \cdot x + b,
\]
где параметры \( a \) и \( b \) нужно подобрать с помощью обучения на обучающей выборке.

\subsection*{Требуется:}
\begin{enumerate}
    \item Используйте \textbf{leave-one-out cross-validation (LOOCV)} для оценки качества модели.
    \item Для каждой итерации используйте метод наименьших квадратов для подбора параметров \( a \) и \( b \) по формулам:
    \[
    a = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2}, \quad b = \bar{y} - a \cdot \bar{x}.
    \]
    \item Проведите LOOCV:
    \begin{itemize}
        \item На каждой итерации оставьте одно наблюдение для тестирования и обучайте модель на оставшихся данных.
        \item Рассчитайте параметры \( a \) и \( b \) для каждой подвыборки.
        \item Используя найденные параметры, предскажите \( y \) для отложенного объекта.
    \end{itemize}
    \item Рассчитайте среднеквадратическую ошибку (MSE) на тестовых объектах:
    \[
    \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2.
    \]
\end{enumerate}

\subsection*{Данные:}
Таблица с наблюдениями:

\[
\begin{array}{|c|c|c|}
\hline
\text{Объект } i & x_i & y_i \\
\hline
1 & 1 & 0 \\
2 & 2 & 0 \\
3 & 3 & 1 \\
4 & 4 & 1 \\
5 & 5 & 1 \\
6 & 6 & 0 \\
\hline
\end{array}
\]

\section*{Решение задачи LOOCV}


\subsection*{1. Процедура LOOCV:}
\begin{itemize}
    \item На каждой итерации исключаем одно наблюдение из выборки для тестирования.
    \item Обучаем модель на оставшихся наблюдениях.
    \item Рассчитываем параметры линейной модели по формулам:
    \[
    a = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2}, \quad b = \bar{y} - a \cdot \bar{x},
    \]
    где \(\bar{x}\) и \(\bar{y}\) — средние значения \(x\) и \(y\) на обучающей выборке.
    \item Предсказываем \(y\) для тестового объекта:
    \[
    \hat{y} = a \cdot x + b.
    \]
\end{itemize}

\subsection*{2. Итерации:}
Рассмотрим все 6 итераций:
\begin{itemize}
    \item \textbf{Итерация 1:} Тестовый объект \( (x_1 = 1, y_1 = 0) \)
    \begin{itemize}
        \item Обучающая выборка: \( (x, y) = \{(2, 0), (3, 1), (4, 1), (5, 1), (6, 0)\} \).
        \item Найденные параметры: \( a_1, b_1 \).
        \item Предсказание: \( \hat{y}_1 \).
        \item Ошибка: \( (y_1 - \hat{y}_1)^2 \).
    \end{itemize}
    \item \textbf{Итерация 2:} Тестовый объект \( (x_2 = 2, y_2 = 0) \)
    \begin{itemize}
        \item Обучающая выборка: \( (x, y) = \{(1, 0), (3, 1), (4, 1), (5, 1), (6, 0)\} \).
        \item Найденные параметры: \( a_2, b_2 \).
        \item Предсказание: \( \hat{y}_2 \).
        \item Ошибка: \( (y_2 - \hat{y}_2)^2 \).
    \end{itemize}
    \item Аналогично повторяем для всех объектов \( i = 3, 4, 5, 6 \).
\end{itemize}

\subsection*{3. Среднеквадратическая ошибка:}
Рассчитываем MSE:
\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2,
\]
где \( n = 6 \).

\subsection*{4. Результат:}
\[
\text{MSE} \approx 0.653
\]

\section*{Задача: Кросс-валидация для классификации (5-Fold)}

Вам дан набор данных из 10 объектов:
\[
D = \{ (x_1, y_1), (x_2, y_2), \dots, (x_{10}, y_{10}) \},
\]
где \( x_i \) — признак (вещественное число), а \( y_i \) — метка класса (\( 0 \) или \( 1 \)).

Модель классификации представляет собой простое пороговое правило:
\[
\hat{y} =
\begin{cases} 
1, & \text{если } x \geq t, \\
0, & \text{если } x < t,
\end{cases}
\]
где \( t \) — порог, который нужно определить.

\subsection*{Требуется:}
\begin{enumerate}
    \item Разбейте данные на 5 фолдов для \textbf{5-Fold Cross-Validation}.
    \item Для каждого фолда:
    \begin{itemize}
        \item Используйте 4 фолда для обучения (подберите оптимальный порог \( t \)) и 1 фолд для тестирования.
        \item Подберите \( t \), чтобы минимизировать число ошибок классификации (ошибок предсказания).
    \end{itemize}
    \item Рассчитайте среднюю точность (accuracy) на тестовых фолдах:
    \[
    \text{Accuracy} = \frac{\text{Число верных предсказаний}}{\text{Общее число объектов}}.
    \]
\end{enumerate}

\subsection*{Данные:}
Таблица с наблюдениями:

\[
\begin{array}{|c|c|c|}
\hline
\text{Объект } i & x_i & y_i \\
\hline
1 & 1.2 & 0 \\
2 & 2.3 & 0 \\
3 & 2.8 & 0 \\
4 & 3.4 & 1 \\
5 & 4.1 & 1 \\
6 & 4.8 & 1 \\
7 & 5.5 & 1 \\
8 & 6.0 & 1 \\
9 & 6.7 & 0 \\
10 & 7.5 & 0 \\
\hline
\end{array}
\]

\subsection*{Упрощение для решения:}
\begin{itemize}
    \item Разделите данные по порядку: первые 2 объекта в первый фолд, следующие 2 — во второй, и так далее.
    \item Для каждого обучающего фолда подберите порог \( t \), перебрав средние значения между соседними объектами \( x_i \).
    \item Для упрощения расчетов: оптимизация \( t \) и проверка классификации выполняются с помощью простых сравнений.
\end{itemize}

\section*{Решение задачи: Кросс-валидация для классификации (5-Fold)}

\subsection*{Шаг 1: Разбиение данных на 5 фолдов}

Каждый фолд состоит из двух объектов. Разбиение:
\[
\begin{aligned}
\text{Фолд 1:} & \quad \{(1.2, 0), (2.3, 0)\}, \\
\text{Фолд 2:} & \quad \{(2.8, 0), (3.4, 1)\}, \\
\text{Фолд 3:} & \quad \{(4.1, 1), (4.8, 1)\}, \\
\text{Фолд 4:} & \quad \{(5.5, 1), (6.0, 1)\}, \\
\text{Фолд 5:} & \quad \{(6.7, 0), (7.5, 0)\}.
\end{aligned}
\]

\subsection*{Шаг 2: Выбор оптимального порога \( t \) для каждого фолда}

Для обучения используется объединение 4 фолдов, а пятый фолд служит тестовым. 

\subsubsection*{Фолд 1: Тестовый фолд \(\{(1.2, 0), (2.3, 0)\}\)}
Обучающая выборка:
\[
\{(2.8, 0), (3.4, 1), (4.1, 1), (4.8, 1), (5.5, 1), (6.0, 1), (6.7, 0), (7.5, 0)\}.
\]
Проверяем пороги \( t \) (средние значения между \( x_i \)):
\[
\begin{aligned}
t_1 = \frac{2.8 + 3.4}{2} = 3.1, & \quad t_2 = \frac{3.4 + 4.1}{2} = 3.75, \\
t_3 = \frac{4.1 + 4.8}{2} = 4.45, & \quad \dots, \quad t_7 = \frac{6.7 + 7.5}{2} = 7.1.
\end{aligned}
\]
Оптимальный порог \( t = 3.1 \) минимизирует ошибки. Тестируем: обе точки \((1.2, 0)\) и \((2.3, 0)\) классифицируются верно. 

\(\text{Accuracy}_1 = 1.0\).

\subsubsection*{Фолд 2: Тестовый фолд \(\{(2.8, 0), (3.4, 1)\}\)}
Обучающая выборка:
\[
\{(1.2, 0), (2.3, 0), (4.1, 1), (4.8, 1), (5.5, 1), (6.0, 1), (6.7, 0), (7.5, 0)\}.
\]
Оптимальный порог \( t = 3.75 \). Тестируем:
\[
\begin{aligned}
\hat{y}(2.8) = 0 \quad (\text{верно}), & \quad \hat{y}(3.4) = 1 \quad (\text{верно}).
\end{aligned}
\]
\(\text{Accuracy}_2 = 1.0\).

\subsubsection*{Фолд 3: Тестовый фолд \(\{(4.1, 1), (4.8, 1)\}\)}
Обучающая выборка:
\[
\{(1.2, 0), (2.3, 0), (2.8, 0), (3.4, 1), (5.5, 1), (6.0, 1), (6.7, 0), (7.5, 0)\}.
\]
Оптимальный порог \( t = 4.5 \). Тестируем:
\[
\begin{aligned}
\hat{y}(4.1) = 1 \quad (\text{верно}), & \quad \hat{y}(4.8) = 1 \quad (\text{верно}).
\end{aligned}
\]
\(\text{Accuracy}_3 = 1.0\).

\subsubsection*{Фолд 4: Тестовый фолд \(\{(5.5, 1), (6.0, 1)\}\)}
Обучающая выборка:
\[
\{(1.2, 0), (2.3, 0), (2.8, 0), (3.4, 1), (4.1, 1), (4.8, 1), (6.7, 0), (7.5, 0)\}.
\]
Оптимальный порог \( t = 5.75 \). Тестируем:
\[
\begin{aligned}
\hat{y}(5.5) = 1 \quad (\text{верно}), & \quad \hat{y}(6.0) = 1 \quad (\text{верно}).
\end{aligned}
\]
\(\text{Accuracy}_4 = 1.0\).

\subsubsection*{Фолд 5: Тестовый фолд \(\{(6.7, 0), (7.5, 0)\}\)}
Обучающая выборка:
\[
\{(1.2, 0), (2.3, 0), (2.8, 0), (3.4, 1), (4.1, 1), (4.8, 1), (5.5, 1), (6.0, 1)\}.
\]
Оптимальный порог \( t = 6.35 \). Тестируем:
\[
\begin{aligned}
\hat{y}(6.7) = 0 \quad (\text{верно}), & \quad \hat{y}(7.5) = 0 \quad (\text{верно}).
\end{aligned}
\]
\(\text{Accuracy}_5 = 1.0\).

\subsection*{Шаг 3: Средняя точность}
Средняя точность:
\[
\text{Accuracy}_{\text{mean}} = \frac{\text{Accuracy}_1 + \text{Accuracy}_2 + \text{Accuracy}_3 + \text{Accuracy}_4 + \text{Accuracy}_5}{5} = 1.0.
\]

\subsection*{Вывод}
Модель с оптимальными порогами \( t \) классифицировала все объекты правильно на каждом из фолдов. Средняя точность составляет \( \mathbf{100\%} \).


\section*{Задача: Кросс-валидация для оценки среднего значения}

У вас есть набор данных, содержащий измеренные значения некоторой величины:
\[
D = \{ x_1, x_2, x_3, \dots, x_{12} \},
\]
где \(x_i\) — вещественное число. Вам необходимо оценить среднее значение этой величины и одновременно оценить, насколько точно модель предсказывает новые значения, используя технику кросс-валидации.

---

\subsection*{Требуется:}
1. Проведите разбиение данных на \textbf{4 фолда} для выполнения 4-Fold Cross-Validation.  
2. Для каждого фолда:
   \begin{itemize}
       \item Используйте 3 фолда для расчета среднего значения \(\bar{x}\).  
       \item Используйте 1 фолд для тестирования, чтобы рассчитать абсолютное отклонение предсказанного среднего \(\bar{x}\) от истинных значений.
   \end{itemize}
3. Рассчитайте среднее абсолютное отклонение (MAE) по всем тестовым фолдам:
\[
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} \lvert x_i - \bar{x} \rvert,
\]
где \(n\) — количество объектов в тестовых фолдах.

---

\subsection*{Данные:}
Таблица с измерениями:

\[
\begin{array}{|c|c|}
\hline
\text{Объект } i & x_i \\
\hline
1 & 5.1 \\
2 & 4.8 \\
3 & 6.2 \\
4 & 5.7 \\
5 & 5.4 \\
6 & 6.0 \\
7 & 5.3 \\
8 & 4.9 \\
9 & 6.1 \\
10 & 5.8 \\
11 & 5.5 \\
12 & 6.3 \\
\hline
\end{array}
\]

---

\subsection*{Упрощение для решения:}
\begin{itemize}
    \item Разделите данные на 4 фолда последовательно: первые 3 объекта в первый фолд, следующие 3 — во второй и так далее.  
    \item Расчеты среднего \(\bar{x}\) и абсолютных отклонений выполняйте вручную для каждого фолда.  
    \item Итоговая метрика MAE рассчитывается как среднее значение всех абсолютных отклонений.
\end{itemize}


\section*{Решение: Кросс-валидация для оценки среднего значения}

\subsection*{Шаг 1. Разбиение данных на фолды}
Разделим данные \(D = \{5.1, 4.8, 6.2, 5.7, 5.4, 6.0, 5.3, 4.9, 6.1, 5.8, 5.5, 6.3\}\) на 4 фолда:
\[
\text{Фолд 1: } \{5.1, 4.8, 6.2\}, \quad
\text{Фолд 2: } \{5.7, 5.4, 6.0\},
\]
\[
\text{Фолд 3: } \{5.3, 4.9, 6.1\}, \quad
\text{Фолд 4: } \{5.8, 5.5, 6.3\}.
\]

\subsection*{Шаг 2. Расчёт среднего значения и абсолютных отклонений для каждого фолда}
Для каждого фолда используем три других фолда для расчёта среднего значения \(\bar{x}\) и тестируем на оставшемся фолде.

\subsubsection*{Фолд 1 (тест): \{5.1, 4.8, 6.2\}}
Среднее значение \(\bar{x}\), рассчитанное по остальным фолдам:
\[
\bar{x}_1 = \frac{5.7 + 5.4 + 6.0 + 5.3 + 4.9 + 6.1 + 5.8 + 5.5 + 6.3}{9} = 5.67.
\]
Абсолютные отклонения:
\[
|5.1 - 5.67| = 0.57, \quad |4.8 - 5.67| = 0.87, \quad |6.2 - 5.67| = 0.53.
\]

\subsubsection*{Фолд 2 (тест): \{5.7, 5.4, 6.0\}}
Среднее значение \(\bar{x}\), рассчитанное по остальным фолдам:
\[
\bar{x}_2 = \frac{5.1 + 4.8 + 6.2 + 5.3 + 4.9 + 6.1 + 5.8 + 5.5 + 6.3}{9} = 5.55.
\]
Абсолютные отклонения:
\[
|5.7 - 5.55| = 0.15, \quad |5.4 - 5.55| = 0.15, \quad |6.0 - 5.55| = 0.45.
\]

\subsubsection*{Фолд 3 (тест): \{5.3, 4.9, 6.1\}}
Среднее значение \(\bar{x}\), рассчитанное по остальным фолдам:
\[
\bar{x}_3 = \frac{5.1 + 4.8 + 6.2 + 5.7 + 5.4 + 6.0 + 5.8 + 5.5 + 6.3}{9} = 5.64.
\]
Абсолютные отклонения:
\[
|5.3 - 5.64| = 0.34, \quad |4.9 - 5.64| = 0.74, \quad |6.1 - 5.64| = 0.46.
\]

\subsubsection*{Фолд 4 (тест): \{5.8, 5.5, 6.3\}}
Среднее значение \(\bar{x}\), рассчитанное по остальным фолдам:
\[
\bar{x}_4 = \frac{5.1 + 4.8 + 6.2 + 5.7 + 5.4 + 6.0 + 5.3 + 4.9 + 6.1}{9} = 5.49.
\]
Абсолютные отклонения:
\[
|5.8 - 5.49| = 0.31, \quad |5.5 - 5.49| = 0.01, \quad |6.3 - 5.49| = 0.81.
\]

\subsection*{Шаг 3. Итоговая метрика MAE}
Среднее абсолютное отклонение рассчитывается как:
\[
\text{MAE} = \frac{\sum_{i=1}^{12} |x_i - \bar{x}|}{12}.
\]
Подставляем рассчитанные значения:
\[
\text{MAE} = \frac{0.57 + 0.87 + 0.53 + 0.15 + 0.15 + 0.45 + 0.34 + 0.74 + 0.46 + 0.31 + 0.01 + 0.81}{12} = 0.49.
\]

\subsection*{Ответ:}
Среднее абсолютное отклонение (MAE): \boxed{0.49}


\section{Вероятность переобучения}

Рассмотрим объединенную выборку обучение + контроль:
\begin{equation*}
    X^L=\{ x_1, \dots , x_L \} - \text{конечное} \textit{ генеральное множество } \text{объектов};
\end{equation*}
и
\begin{equation*}
    A=\{ a_1, \dots , a_D \} - \text{конечное} \textit{ семейство алгоритмов};
\end{equation*}

т. е. те алгоритмы, среди которых мы выбираем (делаем Model \newline Selection или делаем обучения по обучающей выборке). Пусть при этом функция потерь бинарна, т. е. у нас есть индикатор ошибки (условие того, что алгоритм $a$ ошибается на объекте $x$):
\begin{equation*}
    \mathcal{L} ( a, x ) \equiv I ( a, x ) = [ \text{алгоритм $a$ ошибается на объекте $x$ } ].
\end{equation*}

Тогда естесственным образом возникает матрица ошибок (не путать с матрицей объект-признак) $-$ у нее по строчкам объекты, а по столбцам $-$ наши алгоритмы (каждый столбец $-$ бинарный вектор, на каких объектах ошибся наш алгоритм):

\begin{table}[hbt!]
    \begin{tabular}{c|cccccccc|p{5cm}}
            & $a_1$ & $a_2$ & $a_3$ & $a_4$ & $a_5$ & $a_6$ & $\dots$ & $a_D$ & \\
    \hline
    $x_1$     & 1   & 1   & 0   & \textcolor{green}{\textbf{0}} & 0   & 1   & $\dots$ & 1   & \multirow{3}{*}{\parbox{5cm}{$X^l$ $-$ наблюдаемая (обучающая) выборка длины $l$}} \\
    \dots   & 0   & 0   & 0   & \textcolor{green}{\textbf{0}} & 1   & 1   & $\dots$ & 1   & \\
    $x_l$     & 0   & 0   & 1   & \textcolor{green}{\textbf{0}} & 0   & 0   & $\dots$ & 0   & \\
    \hline
    $x_{l+1}$ & 0   & 0   & 0   & \textcolor{red}{\textbf{1}}   & 1   & 1   & $\dots$ & 0   & \multirow{3}{*}{\parbox{5cm}{$X^k$ $-$ скрытая (контрольная) выборка длины $k=L-l$}} \\
    \dots   & 0   & 0   & 0   & \textcolor{red}{\textbf{1}}   & 0   & 0   & $\dots$ & 1   & \\
    $x_L$     & 0   & 1   & 1   & \textcolor{red}{\textbf{1}}   & 1   & 1   & $\dots$ & 0   & \\
    \end{tabular}
    \caption{$L \times D$ $-$ матрица ошибок с попарно различными столбцами}
\end{table}

На столбце $a_4$ мы как раз видим переобучение $-$ на обучающих объектах 0 ошибок, а на контрольных $-$ все ошибки (идеально плохая ситуация). Фишка в том, что мы начнем разбивать генеральную выборку всеми возможными способами на обучение и контроль (их всего $C_{l+k}^l$). Обозначим
\begin{equation*}
    n(a, X)= \sum_{x \in X} I(a, x) - \text{число ошибок } a \in A \text{ на выборке } X \subset X^L;
\end{equation*}
\begin{equation*}
    \nu(a, X)= n(a, X)/ | X | - \text{частота ошибок } a \text{ на выборке } X.
\end{equation*}

Нам придется сравнивать частоты ошибок на обучении и на контроле. Их разность $-$ это и есть переобученность. Посмотрим на примере, откуда вообще берется матрица ошибок:, 

\textbf{Пример 1.}

Пусть у нас есть выборка из 10 объектов, 5 объектов одного класса и 5 другого. Строим линейные классификаторы. В матрице ошибок есть один нулевой вектор (линейный классификатор без ошибок см. рис. \ref{fig:pic1}), 5 векторов с одной ошибкой (рис. \ref{fig:pic2} и т. д.). Вот откуда берется матрица ошибок. Максимально в ней может быть $2^l$ вектор-столбцов.

  \begin{figure}[hbt!]
    \begin{tikzpicture}
        \begin{axis}[
            axis lines = box,
            xmin=-4, xmax=12,
            ymin=-4, ymax=8,
        ]
    
        % Синие точки
        \addplot[only marks, mark=*, color=blue] coordinates {(5, 6) (6, 3) (10, 4) (9, 7) (11, 6)};
        \node[black] at (axis cs:5, 6) [above] {$x_4$};
        \node[black] at (axis cs:6, 3) [above right] {$x_5$};
        \node[black] at (axis cs:10, 4) [above right] {$x_6$};
        \node[black] at (axis cs:9, 7) [below left] {$x_9$};
        \node[black] at (axis cs:11, 6) [above] {$x_{10}$};
    
        % Красные точки
        \addplot[only marks, mark=*, color=red] coordinates {(-1, 2) (3, 2) (5, -3) (3, -2) (-3, -1)};
        \node[black] at (axis cs:-1, 2) [above left] {$x_1$};
        \node[black] at (axis cs:3, 2) [above left] {$x_2$};
        \node[black] at (axis cs:5, -3) [below right] {$x_3$};
        \node[black] at (axis cs:3, -2) [below left] {$x_7$};
        \node[black] at (axis cs:-3, -1) [below right] {$x_8$};
    
        % Фиолетовый отрезок
        \addplot[color=purple, thick] coordinates {(8, -3) (0, 7)};
        
        \end{axis}
    \end{tikzpicture}
    \caption{линейный классификатор без ошибок}
    \label{fig:pic1}
  \end{figure}

  \begin{figure}[hbt!]
    \begin{tikzpicture}
        \begin{axis}[
            axis lines = box,
            xmin=-4, xmax=12,
            ymin=-4, ymax=8,
        ]
    
        % Синие точки
        \addplot[only marks, mark=*, color=blue] coordinates {(5, 6) (6, 3) (10, 4) (9, 7) (11, 6)};
        \node[black] at (axis cs:5, 6) [above] {$x_4$};
        \node[black] at (axis cs:6, 3) [above right] {$x_5$};
        \node[black] at (axis cs:10, 4) [above right] {$x_6$};
        \node[black] at (axis cs:9, 7) [below left] {$x_9$};
        \node[black] at (axis cs:11, 6) [above] {$x_{10}$};
    
        % Красные точки
        \addplot[only marks, mark=*, color=red] coordinates {(-1, 3) (3, 2) (5, -3) (3, -2) (-3, -1)};
        \node[black] at (axis cs:-1, 3) [above left] {$x_1$};
        \node[black] at (axis cs:3, 2) [above left] {$x_2$};
        \node[black] at (axis cs:5, -3) [below right] {$x_3$};
        \node[black] at (axis cs:3, -2) [below left] {$x_7$};
        \node[black] at (axis cs:-3, -1) [below right] {$x_8$};
    
        % Фиолетовый отрезок
        \addplot[color=purple, thick] coordinates {(4, -3) (4, 6)};
        \addplot[color=purple, thick] coordinates {(4, 7) (10, -3)};
        \addplot[color=purple, thick] coordinates {(6, -3) (5.5, 7)};
        \addplot[color=purple, thick] coordinates {(-3, 2.5) (11, 2)};
        \addplot[color=purple, thick] coordinates {(8, -3) (-3, 6)};
        
        \end{axis}
    \end{tikzpicture}
    \caption{линейный классификатор с 1 ошибкой}
    \label{fig:pic2}
  \end{figure}

\begin{table}[hbt!]
    \begin{tabular}{c|c|ccccc|c}
		$x_1$ & 0 & 1 & 0 & 0 & 0 & 0 & \dots \\
    $x_2$ & 0 & 0 & 1 & 0 & 0 & 0 & \dots \\
		$x_3$ & 0 & 0 & 0 & 1 & 0 & 0 & \dots \\
    $x_4$ & 0 & 0 & 0 & 0 & 1 & 0 & \dots \\
    $x_5$ & 0 & 0 & 0 & 0 & 0 & 1 & \dots \\
    $x_6$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    $x_7$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    $x_8$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    $x_9$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    $x_{10}$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    \end{tabular}
    \caption{матрица ошибок для примера 1}
\end{table}

Наша задача будет оценивать вероятность переобучения. Для начала дадим несколько определений.
Вероятностное пространтво $-$ это равновероятное разбиение выборки на 2 части (train $X^l$ и test $X^k$). Интерпретация этому это гипотеза, что наша выборка IID (independent and identically distributed). Т. е. как бы мы эту выборку не упорядочивали, все ее упорядочивания равновероятны (как бы мы ее не разбивали на две части, все разбиения равновероятны). Это есть гипотеза простой выборки.

\textit{Замечание.} С другой стороны на это можно смотреть, как на Complete Cross Validation (полный скользящий контроль). Всеми способами разбиваем выборку на train и test. Потом по всем этим способам вероятность любого события, зависящая от этого разбиения, усредняем по всем разбиениям. В этой вероятностной интерпретации очень удобно, что математическое ожидание есть просто усреднение по всем разбиениям выборки
\begin{equation*}
    P \equiv E \equiv \frac{1}{C_L^l} \sum_{X^l \subset X^L}.
\end{equation*}

Переобученность $-$ это разность частот ошибок на $X^k$ и на $X^l$ (обучились на $X^l$, частоту ошибок посчитали на $X^k$, частота ошибок нормирована от 0 до 1):
\begin{equation*}
    \delta (\mu, X^l, X^k)=\nu (\mu(X^l), X^k ) - \nu(\mu(X^l), X^l ).
\end{equation*}

Переобучение $-$ это событие $\delta (\mu, X^l, X^k) \geq \varepsilon$ для фиксированного $\varepsilon$.

Основная наша задача $-$ оценить \textit{вероятность} переобучения (вероятность в смысле доли разбиения выборки, на которых $\delta$ оказалась $\geq \varepsilon$ при заданном $\varepsilon$):
\begin{equation*}
    R_{\varepsilon}(\mu, X^L) = P [\delta(\mu, X^l, X^k) \geq \varepsilon].
\end{equation*}

Теперь наша задача $-$ научиться сверху оценивать эту величину. Рассмотрим простейший, но важный частный случай.

Пусть у нас нет никакого выбора алгоритма, научимся оценивать вероятность переобучения хотя бы для одного отдельно взятого алгоритма, т. е. для одного вектор-столбца матрицы ошибок.
Пусть $A = {a}$ $-$ одноэлементарное множество, $m=n(a, X^L)$. Тогда вероятность переобучения есть вероятность большого отклонения частот ошибок в двух подвыборках:

\begin{equation*}
    R_{\varepsilon}(a, X^L) = P [\nu(a, X^k) - \nu(a, X^l) \geq \varepsilon].
\end{equation*}

\textbf{Теорема} Для любой выборки $X^l$, любого $\varepsilon \in [0, 1]$ вероятность большого отклонения частот ошибок в двух подвыборках для фиксированного вектора ошибок:
$$R_{\varepsilon}(a, X^L)=\mathcal{H}_L^{l, m}(\frac{l}{L}(m-\varepsilon k)),$$
где $\mathcal{H}_L^{l, m}(x)=\sum_{s=0}^{\lfloor x \rfloor}\frac{C_m^s C_{L-m}^{l-s}}{C_L^l}$ $-$ функция гипергеометрического распределения (ее левый хвост).

\textbf{Доказательство.}
$\square$ Обозначим число ошибок на обучении как $s=n(a, X^l)$. Аналогия со 2 задачей из упражнения,  где $m$ $-$ количество объектов с ошибками, $l$ $-$ обучающая выборка (гипергеометрическое распределение):
\begin{equation*}
    P[n(a, X^l)=s]=C_m^s C_{L-m}^{l-s}/C_L^l.
\end{equation*}
Распишем $R_{\varepsilon}$, подставив в него $\nu(a, X^k)=\frac{m-s}{k}$, $\nu(a, X^l)=\frac{s}{l}$ (частота ошибок на обучении $\frac{s}{l}$, а на контроле $\frac{m-s}{k}$) и учитывая тот факт, что $\frac{m-s}{k}-\frac{s}{l}$ есть переобученность:
\begin{multline*}
    R_{\varepsilon}(a, X^L)=P[\nu(a, X^k)-\nu(a, X^l) \geq \varepsilon] = \\
    = \sum_{s=0}^l [\underbrace{\frac{m-s}{k}-\frac{s}{l} \geq \varepsilon}_{s \leq \frac{l}{L}(m-\varepsilon k)}]\underbrace{P[n(a, X^l)=s]}_{C_m^s C_{L-m}^{l-s}/C_L^l}=\mathcal{H}_L^{l, m}(\frac{l}{L}(m-\varepsilon k)).
\end{multline*}

При это мы получили ограничение на $s$, которое является следствием того, что переобученность $\leq \varepsilon$. Наша оценка $-$ левый хвост гипергеометрического распределения.
$\blacksquare$

Посмотрим как это выглядит на картинке. На оси $x$ отложено $m$ $-$ общее число ошибок на полной выборке, по оси $y$ откладывается число ошибок на обучающей выборке. На графике \ref{fig:pic3} видна узкая полоска $-$ \textit{явление концентрации вероятностной меры}. Это очень важное явление и в теории вероятности, и в машинном обучении, и в Computational learning theory. Это основной теоретический момент, из которого могут быть получены различные оценки (красная полоска). При том чем больше будет длина выборки, тем уже будет относительная ширина этой полоски.

Предсказание числа $m=n(a, X^L)$ по числу $s=n(a, X^l)$ возможно благодаря узости гипергеометрического пика, причем при $l,k \rightarrow \infty$ он сужается, и $\nu(a, X^l) \rightarrow \nu(a, X^k)$ (явление концентрации вероятности, закон больших чисел).

Гипергеометрическое распределение нам говорит, что если мы знаем $m$ (общее число ошибок на полной выборке), то мы можем предсказать диапазон изменений для $s$, т. е. сколько у нас ошибок попадет в обучение. Значит будем знать $m-s$, сколько ошибок попадет в контроль. Но в реальной ситуации нам приходиться обращать это гипергеометрическое распределение, т. к. мы знаем сколько ошибок у нас попало в обучение. Мы знаем что у нас по $y$ и можем провести горизонтальную линию и сказать, в каком у нас диапазоне могло бы быть $m$, т. е. в каком диапазоне могло бы лежать общее число ошибок на объединенной выборке. А $m-s$ это число ошибок на контроле.

\usetikzlibrary{intersections}
\usepgfplotslibrary{fillbetween}

\begin{figure}[hbt!]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \begin{tikzpicture}[scale=0.8]
            \begin{axis}[
                grid=both,
                xlabel={$h(s|m)$},
                ylabel={$s$},
                ymin=-5, ymax=105,
                xmin=-0.01, xmax=0.13,
                tick align=outside
            ]
                \addplot[red, thick, domain=0:50, samples=100] (0.12*exp(-(x-25)*(x-25)),x);
                \addplot[color=black, thick, dashed] coordinates {(0, 0) (0.12, 0)};
                \addplot[color=black, thick, dashed] coordinates {(0, 20) (0.12, 20)};
                \addplot[color=black, thick, dashed] coordinates {(0, 30) (0.12, 30)};
                \addplot[color=black, thick, dashed] coordinates {(0, 50) (0.12, 50)};
            \end{axis}
        \end{tikzpicture}
        \caption{$h(s|m)$ при $m=50$}
        \label{fig:pic3}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \begin{tikzpicture}[scale=0.8]
            \begin{axis}[
                grid=both,
                xlabel={$m$},
                ylabel={$s$},
                xmin=-5, xmax=205,
                ymin=-5, ymax=105,
            ]
                % Main diagonal
                \addplot[red, domain=0:200, samples=100, dashdotted] {x/2};
                % Shaded region
                \addplot[name path=A, domain=10:200, samples=100, thick, dashed] {x/2 - 5};
                \addplot[name path=B, domain=0:190, samples=100, thick, dashed] {x/2 + 5};
    
                \addplot[name path=seg1, color=black, thick] coordinates {(0, 0) (100, 100)};
                \addplot[name path=seg2, color=black, thick] coordinates {(100, 100) (200, 100)};
                \addplot[name path=seg3, color=black, thick] coordinates {(200, 100) (100, 0)};
                \addplot[name path=seg4, color=black, thick] coordinates {(100, 0) (0, 0)};
                \addplot[red, opacity=0.3] fill between[of=seg1 and seg4];
                \addplot[red, opacity=0.3] fill between[of=seg2 and seg3];
    
                \addplot[red, opacity=0.3] fill between[of=A and B];
                \addplot[color=black, thick, dashed] coordinates {(0, 50) (50, 50)};
                \addplot[color=black, thick, dashed] coordinates {(0, 30) (50, 30)};
                \addplot[color=black, thick, dashed] coordinates {(0, 20) (50, 20)};
                \addplot[color=black, thick, dashed] coordinates {(0, 0) (50, 0)};
                \addplot[color=black, <->] coordinates {(50, 0) (50, 50)};
            \end{axis}
        \end{tikzpicture}
        \caption{$h(s|m)$ при $L=200, k=100$}
        \label{fig:pic4}
    \end{subfigure}
    \caption{Гипергеометрическое распределение $h(s|m)$}
\end{figure}

\textbf{Задача 1.} Сколько линейных классификаторов с двумя ошибками из примера 1?

\textbf{Решение.}

Для решения задачи необходимо посмотреть сколько существует различных способов разделить объекты на рисунке \ref{fig:pic1}, чтобы объектов одного класса было на 2 больше, чем другого. Приведем ответ в виде таблицы:

\begin{table}[hbt!]
    \begin{tabular}{c|cccccccc}
		$x_1$ & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 \\
    $x_2$ & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
		$x_3$ & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 \\
    $x_4$ & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\
    $x_5$ & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 \\
    $x_6$ & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\
    $x_7$ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    $x_8$ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    $x_9$ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 $x_{10}$ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \end{tabular}
    \caption{все возможные разбиения с 2 ошибками}
\end{table}

\textbf{Задача 2.} В урне $L$ шаров, $m$ из них черные, остальные белые; извлекаем $l$ шаров наугад. Какова вероятность, что ровно $s$ из них черные?

\textbf{Решение.}

Обозначим:
$N = L$ $-$ общее количество шаров в урне,
$m$ $-$ количество черных шаров,
$N - m$ $-$ количество белых шаров,
$l$ $-$ общее количество извлеченных шаров,
$s$ $-$ количество черных шаров среди извлеченных.

Чтобы найти вероятность, нам нужно рассмотреть, сколько способов существует для выбора $s$ черных шаров и $l - s$ белых шаров из общего количества.

Выбрать $s$ черных шаров из $m$ черных можно $C_m^s$ способами.

А выбрать $l - s$ белых шаров из $N - m$ белых $-$ $ C_{N - m}^{l - s}$ способами.

Общее количество способов выбрать $l$ шаров из $N$ есть $C_N^l$.

Таким образом, вероятность того, что из $l$ извлеченных шаров ровно $s$ будут черными, будет равна отношению числа благоприятных исходов к общему числу исходов:

$$
P(X = s) = \frac{C_{m}^{s} \cdot C_{N - m}^{l - s}}{C_{N}^{l}}
$$

\textbf{Задача 3.} Как посчитать количество рыб в пруду?

\textbf{Решение.} Выловим некоторое случайное подмножество рыб, пометим их, а потом выпустим обратно в пруд. Через некоторое время рыбы в пруду перемешаются (важно, чтобы они успели перемешаться), опять вылавливаем некоторое количество рыб и смотрим, какая доля среди них $-$ меченная. По этим данным, очевидно, можно найти общее количество рыб в пруду.


\section{Статистические критерии в машинном обучении}
\subsection{Теория}

Статистические инструменты используются для отбора, извлечения и преобразования наиболее релевантных признаков. Например, коэффициент корреляции Пирсона, ранговый коэффициент Спирмена, коэффициент корреляции ANOVA, ранговый коэффициент Кендалла и критерий  Хи-квадрат \\

В данном обзоре рассмотрим приложения математической статистики в машинном обучении – точнее, в отборе признаков для обучения модели.  \\

Мотивация: Преимущества хорошо подобранных признаков в датасете очевидны: это улучшает точность в обучении с учителем и без, уменьшает время и память, необходимые для корректной работы, помогает ослабить проклятие размерности (экспоненциальный рост необходимых данных). \\

Одним из основных методов, используемых для отбора признаков, является анализ корреляции. Корреляция позволяет определить, насколько сильно связаны между собой различные признаки и целевая переменная. Признаки с высокой корреляцией с целевой переменной могут быть отобраны для дальнейшего анализа, в то время как признаки, которые не имеют значительной связи, могут быть исключены. Это помогает избежать проблем многоколлинеарности, когда несколько признаков предоставляют одинаковую информацию.\\

Другим важным инструментом является тестирование гипотез. С помощью статистических тестов, таких как t-тест или ANOVA, можно оценить значимость отдельных признаков в контексте целевой переменной. Например, если мы имеем дело с задачей классификации, мы можем использовать тесты для определения того, какие признаки значительно различаются между классами. Это позволяет сосредоточиться на наиболее информативных признаках и исключить те, которые не вносят существенного вклада в модель.\\

Методы селекции на основе значимости также широко применяются в практике. Алгоритмы, такие как LASSO (Least Absolute Shrinkage and Selection Operator), используют регуляризацию для уменьшения коэффициентов менее значимых признаков до нуля, что автоматически исключает их из модели. Это не только упрощает модель, но и помогает избежать переобучения — проблемы, когда модель слишком точно подстраивается под обучающие данные и теряет способность обобщать на новых данных.\\

Методы оценки производительности модели также зависят от правильного отбора признаков. Кросс-валидация позволяет оценить, как изменения в наборе признаков влияют на общую производительность модели. Сравнение различных моделей с разными наборами признаков помогает выбрать оптимальный вариант, который обеспечивает наилучшие результаты.\\

Кроме того, современные подходы к машинному обучению, такие как ансамблевые методы (например, Random Forest), также используют статистические методы для оценки важности признаков. В таких методах важность каждого признака может быть оценена по тому, как сильно он влияет на уменьшение ошибки предсказания модели. \\

\subsection{Задачи}

1. Анализ корреляции\\
У вас есть набор данных с 5 признаками (X1, X2, X3, X4, X5) и целевой переменной Y. Вы хотите выяснить, какие признаки имеют наибольшую корреляцию с Y.

\textit{Решение:\\
1. Рассчитайте коэффициенты корреляции Пирсона для каждого признака относительно Y.\\
2. Сравните полученные значения и выберите признаки с наибольшими абсолютными значениями коэффициента корреляции.}
   
2. Тестирование гипотез\\
Вы хотите проверить, есть ли статистически значимая разница между двумя группами данных (группа A и группа B) по признаку X. У вас есть данные о значениях X для обеих групп.

\textit{Решение:\\
1. Проведите t-тест для независимых выборок.\\
2. Оцените p-значение для определения значимости.}

3. Регуляризация LASSO \\
У вас есть набор данных с несколькими признаками и целевой переменной. Вы хотите использовать метод LASSO для отбора наиболее значимых признаков.

\textit{Решение:\\
1. Импортируйте библиотеку Lasso из sklearn.\\
2. Подготовьте данные и обучите модель LASSO.\\
3. Оцените важность признаков на основе полученных коэффициентов.\\}


\section{Кросс-валидация}

\subsection{Теория}

Кросс-валидация — это процедура для оценки качества работы модели, которая позволяет более точно оценивать, как модель будет работать на новых, невидимых данных. Основная идея заключается в разбиении данных на несколько частей и обучении модели на разных комбинациях этих частей. При этом  проверять качество модели необходимо на оставшихся данных.

\subsubsection{Hold-out}

В этом методе данные просто разделяются на train и test. После этого происходит обучение на train и проверка качества на test. При этом важно перемешивать данные, потому что в противном случае могут появиться неожиданные <<спецэффекты>>. Например, в изначальных данные может быть, что первые 80\% --- это изображения с кошками, а остальные 20\% --- с собаками. Если при этом цель --- научить модель различать кошек и собак, то очень важные всё перемешать, чтобы не оказалось, что в train попали только кошки.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth/2]{hold_out.png}
	\caption{Hold-out}
	\label{img:hold-out}
\end{figure}

\subsubsection{k-Fold}

Это самый распространенный метод кросс-валидации, в нём данные разбиваются на k подмножеств. Модель обучается k раз, каждый раз используя одно подмножество в качестве тестовой выборки, а остальные k-1 как тренировочные. В конце ошибкой модели считается либо средняя полученная ошибка по всем выборам тестового множества, либо вычисляется на отдельно отложенном валидационном множестве. Это позволяет использовать все доступные данные для обучения и тестирования, что особенно полезно в случаях, когда данные ограничены.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth/2]{k-fold.png}
	\caption{k-Fold}
	\label{img:k-fold}
\end{figure}

Можно сделать вывод, что кросс-валидация помогает избежать переобучения и оптимизировать гиперпараметры моделей засчёт того, что модель много раз обучается и тестируется на разных подмножествах одних и тех же данных.

\subsection{Задачи (\href{https://education.yandex.ru/handbook/ml/article/kross-validaciya}{источник})}

\subsubsection{Задача 1}
Пример из практики Yandex.Research — как вы думаете, что не так с графиком обучения данной модели?

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth/2]{problem-1.png}
	\caption{Задача 1}
	\label{img:problem-1}
\end{figure}

\textit{Решение}
На графике видна периодичность по числу итераций! По большим пикам можно вычислить места, где проход по данным начался заново. Кроме того, график в конце ползёт вниз, что означает, что модель уже начала переобучаться, выучив последовательность данных на трейне и используя эту информацию больше, чем сами данные.

Если данные перемешать, то график обучения станет таким:

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth/2]{sol-1.png}
	\caption{Решение задачи 1}
	\label{img:sol-1}
\end{figure}

\subsubsection{Задача 2}

Пусть нужно обучить модель, которая должна предсказывать погоду. Есть исторические данные за последние 10 лет. Можно ли как обычно разделять данные на train и test, произвольно перемешивая их? Если нет, то как нужно разделять данные?

\textit{Решение}
Нет, так делать нельзя, потому что в таком случае у модели при обучении будет доступ к данным из <<будущего>>, которые он как раз и должна предсказывать, а это некорректно. Правильно будет разделить данные по времени: самые старые --- train, самые новые -- test.

\subsubsection{Задача 3}

А как сделать кросс-валидацию в условиях задачи 2?

\textit{Решение}

Нужно сделать несколько пар (train, test), но так, чтобы модель никогда не получала лишних данных из будущего. С учётом особенностей фолды в кросс-валидации для временных рядов располагаются вдоль временной оси так, как показано на следующей картинке:

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth/2]{sol-3.png}
	\caption{Решение задачи 3}
	\label{img:sol-3}
\end{figure}
